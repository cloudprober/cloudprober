<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>How To on</title><link>https://cloudprober.org/docs/how-to/</link><description>Recent content in How To on</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 04 Oct 2023 17:24:32 -0700</lastBuildDate><atom:link href="https://cloudprober.org/docs/how-to/index.xml" rel="self" type="application/rss+xml"/><item><title>Alerting</title><link>https://cloudprober.org/docs/how-to/alerting/</link><pubDate>Wed, 04 Oct 2023 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/alerting/</guid><description>You can configure Cloudprober to send alerts on probe failures. Alerts are configured per probe and each probe can have multiple alerts with independent configuration. Alert configuration consists of mainly two parts:
Alert condition Notification config Alert Condition #
Alert condition is defined in terms of number of failures (failures) out of a number of attempts (total). For example, if alert condition is specified as: condition {failures: 3, total: 5}, an alert will be triggered if 3 probes have failed out of the last 5 attempts.</description></item><item><title>External Probe</title><link>https://cloudprober.org/docs/how-to/external-probe/</link><pubDate>Tue, 01 Nov 2022 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/external-probe/</guid><description>External probe type allows you to run arbitrary, complex probes through Cloudprober. An external probe runs an independent external program for actual probing. Cloudprober calculates probe metrics based on program&amp;rsquo;s exit status and time elapsed in execution.
Cloudprober also allows external programs to provide additional metrics. Every message sent to stdout will be parsed as a new metrics to be emitted. For general logging you can use another I/O stream like stderr.</description></item><item><title>Kubernetes Targets</title><link>https://cloudprober.org/docs/how-to/k8s_targets/</link><pubDate>Tue, 01 Nov 2022 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/k8s_targets/</guid><description>Cloudprober supports dynamic discovery of Kubernetes resources (e.g. pods, endpoints, ingresses, etc) through the targets type k8s.
For example, the following config adds an HTTP probe for the endpoints named cloudprober (equivalent to running kubectl get ep cloudprober).
probe { name: &amp;quot;pod-to-endpoints&amp;quot; type: HTTP targets { # Equivalent to kubectl get ep cloudprober k8s { endpoints: &amp;quot;cloudprober&amp;quot; } } # Note that the following http_probe automatically uses target's discovered # port.</description></item><item><title>Running On Kubernetes</title><link>https://cloudprober.org/docs/how-to/run-on-kubernetes/</link><pubDate>Tue, 01 Nov 2022 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/run-on-kubernetes/</guid><description>Kubernetes is a popular platform for running containers, and Cloudprober container runs on Kubernetes right out of the box. This document shows how you can run Cloudprober on kubernetes, use ConfigMap for config, and discover kubernetes targets automatically.
â“˜ If you use helm charts for k8s installations, Cloudprober helm chart provides the most convenient way to run Cloudprober on k8s.
ConfigMap #
In Kubernetes, a convenient way to provide config to containers is to use config maps.</description></item><item><title>Additional Labels</title><link>https://cloudprober.org/docs/how-to/additional-labels/</link><pubDate>Sat, 01 Oct 2022 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/additional-labels/</guid><description>You can add additional labels to probe metrics using a probe-level field: additional_label. An additional label&amp;rsquo;s value can be static, or it can be determined at the run-time: from the environment that the probe is running in (e.g. GCE instance labels), or target&amp;rsquo;s labels.
Example config here demonstrates adding various types of additional labels to probe metrics. For this config (also listed below for quick rerefence):
if ingress target has label &amp;ldquo;fqdn:app.</description></item><item><title>Validators</title><link>https://cloudprober.org/docs/how-to/validators/</link><pubDate>Sat, 01 Oct 2022 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/validators/</guid><description>Validators allow you to run checks on the probe request output (if any). For example, you can specify if you expect the probe output to match a certain regex or return a certain status code (for HTTP). You can configure more than one validators and all validators should succeed for the probe to be marked as success.
probe { name: &amp;quot;google_homepage&amp;quot; type: HTTP targets { host_names: &amp;quot;www.google.com&amp;quot; } interval_msec: 10000 # Probe every 10s # This validator should succeed.</description></item><item><title>Percentiles, Histograms, and Distributions</title><link>https://cloudprober.org/docs/how-to/percentiles/</link><pubDate>Thu, 01 Sep 2022 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/percentiles/</guid><description>Percentiles give you a deeper insight into how your system is behaving. For example, if your application&amp;rsquo;s response latency is very low 94 times out 100 but very high for the remaining 6 times, your average latency will still be low but it won&amp;rsquo;t be a great experience for your users. In other words, this is the case where your 95th percentile latency is high, even though your average and median (50th-%ile) latency is very low.</description></item><item><title>Targets</title><link>https://cloudprober.org/docs/how-to/targets/</link><pubDate>Tue, 25 Oct 2016 17:24:32 -0700</pubDate><guid>https://cloudprober.org/docs/how-to/targets/</guid><description>Cloudprober probes usually run against some targets1 to check those targets' status, such as an HTTP probe to your APIs servers, or PING/TCP probes to a third-party provider to verify network connectivity to them. Each probe can have multiple targets. If a probe has multiple targets, Cloudprober runs parallel probes for each target. This page further explains how targets work in Cloudprober.
Dynamically Discovered Targets #
One of the core features of Cloudprober is the automatic and continuous discovery of targets.</description></item><item><title>Built-in Servers</title><link>https://cloudprober.org/docs/how-to/built-in-servers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cloudprober.org/docs/how-to/built-in-servers/</guid><description>Cloudprober comes with some custom servers that can be enabled through configuration. These servers can act as targets for the other probes &amp;ndash; for example, you can run two Cloudprober instances on two different machines and have one instance&amp;rsquo;s servers act as targets and other instance probe those targets.
These servers can come in handy when the goal is to monitor the underlying infrastructure: e.g. network or load balancers.
Cloudprober (probes) ===(Network)===> Cloudprober (servers) HTTP Server #
server { type: HTTP http_server { port: 8080 } } This creates an HTTP server that responds on the port 8080.</description></item><item><title>Extending Cloudprober</title><link>https://cloudprober.org/docs/how-to/extensions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cloudprober.org/docs/how-to/extensions/</guid><description>Cloudprober allows you to extend it across &amp;ldquo;probe&amp;rdquo; and &amp;ldquo;target&amp;rdquo; dimensions, that is, you can add new probe and target types to it without having to fork the entire codebase. Note that to extend cloudprober in this way, you will have to maintain your own cloudprober binary (which is mostly a wrapper around the &amp;ldquo;cloudprober package&amp;rdquo;), but you&amp;rsquo;ll be able to use rest of the cloudprober code from the common location.</description></item></channel></rss>